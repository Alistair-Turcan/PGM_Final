{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy as cp\n",
    "from cupy.fft import fft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#from scipy.fftpack import fft\n",
    "from scipy.optimize import minimize\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precompute_values_gpu(betX, bn=2**7):\n",
    "    \n",
    "    m = len(betX)\n",
    "    bX = betX.reshape(1, m)\n",
    "    minX = cp.mean(bX) - (5 * cp.std(bX))\n",
    "    maxX = cp.mean(bX) + (5 * cp.std(bX))\n",
    "    dX = (maxX - minX) / (bn - 1)\n",
    "    minX = minX - dX/2\n",
    "    maxX = maxX + dX/2\n",
    "    bXi = cp.ceil((bX - minX) / dX).astype(int) \n",
    "    bXi[bXi < 1] = 1\n",
    "    bXi[bXi > bn] = bn\n",
    "    j = cp.arange(bn)\n",
    "    vi = 2 * cp.pi * (j - bn/2) / (maxX - minX - dX)\n",
    "    Rx = vi\n",
    "    Rx_sq_half = -0.5 * Rx**2\n",
    "    mf_init = -2 * cp.log(cp.complex128(-1)) * ((minX + dX/2) / (maxX - minX - dX)) * j\n",
    "    mf = mf_init\n",
    "    FFTmod_init = (1 / (maxX - minX - dX)) * (cp.complex128(-1))**(bn * ((minX + dX/2) / (maxX - minX - dX)) + j)\n",
    "    FFTmod = FFTmod_init\n",
    "    flat_bXi = bXi.flatten() - 1\n",
    "\n",
    "    # Note: if you need to return the arrays back to CPU memory, use cp.asnumpy(...)\n",
    "    return m, Rx, Rx_sq_half, mf, FFTmod, flat_bXi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precompute_values(betX, bn=2**7):\n",
    "    m = len(betX)\n",
    "    bX = np.array(betX).reshape(1, m)\n",
    "    minX = np.mean(bX) - (5 * np.std(bX))\n",
    "    maxX = np.mean(bX) + (5 * np.std(bX))\n",
    "    dX = (maxX - minX) / (bn - 1)\n",
    "    minX = minX - dX/2\n",
    "    maxX = maxX + dX/2\n",
    "    bXi = np.ceil((bX - minX) / dX).astype(int) \n",
    "    bXi[bXi < 1] = 1\n",
    "    bXi[bXi > bn] = bn\n",
    "    j = np.arange(bn)\n",
    "    vi = 2 * np.pi * (j - bn/2) / (maxX - minX - dX)\n",
    "    Rx = np.array(vi)\n",
    "    Rx_sq_half = -0.5 * Rx**2\n",
    "    mf_init = -2 * np.log(np.complex128(-1)) * ((minX + dX/2) / (maxX - minX - dX)) * j\n",
    "    mf = np.array(mf_init)\n",
    "    FFTmod_init = (1 / (maxX - minX - dX)) * (np.complex128(-1))**(bn * ((minX + dX/2) / (maxX - minX - dX)) + j)\n",
    "    FFTmod = np.array(FFTmod_init)\n",
    "    flat_bXi = bXi.flatten() - 1\n",
    "\n",
    "    # Return the precomputed values\n",
    "    return m, Rx, Rx_sq_half, mf, FFTmod, flat_bXi\n",
    "\n",
    "def singleTrait_likelihood(theta, betX, w8s, nX, m, Rx, Rx_sq_half, mf, FFTmod, flat_bXi, bn=2**7):\n",
    "    # Transfer arrays to GPU memory\n",
    "    theta = cp.array(theta)\n",
    "    #betX = cp.array(betX)\n",
    "    #w8s = cp.array(w8s)\n",
    "    #Rx = cp.array(Rx)\n",
    "    #Rx_sq_half = cp.array(Rx_sq_half)\n",
    "    #mf = cp.array(mf)\n",
    "    #FFTmod = cp.array(FFTmod)\n",
    "    #flat_bXi = cp.array(flat_bXi)\n",
    "\n",
    "    piX = cp.abs(theta[0])\n",
    "    h2X = cp.abs(theta[1])\n",
    "    iX = cp.abs(theta[2])\n",
    "    \n",
    "    sigX_sq = h2X / (piX * m)\n",
    "    Rp = iX / nX\n",
    "\n",
    "    Ax_sq = cp.repeat(sigX_sq, bn)\n",
    "    Qx = cp.repeat(piX, bn)\n",
    "    Lx = - (1 - cp.exp(Ax_sq * Rx_sq_half)) * Qx\n",
    "    Le = (Rp * Rx_sq_half)\n",
    "\n",
    "    phi = cp.exp(Lx + Le + mf)\n",
    "    FFT = fft(phi)\n",
    "    FFT0 = cp.real(FFT * FFTmod)\n",
    "\n",
    "    pfE = FFT0[flat_bXi]\n",
    "    my_w8s = w8s[pfE > 0]\n",
    "    pfE = pfE[pfE > 0]\n",
    "\n",
    "    logL = -m * cp.mean(cp.log(pfE * my_w8s))\n",
    "    \n",
    "    return logL.item()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def precompute_values_twoStep_gpu(betXY, piX, piU, piY, nX, nY, bn=2**8):\n",
    "    \n",
    "    m = betXY.shape[0]\n",
    "\n",
    "    bX = betXY[:, 0].reshape(1, 1, m)\n",
    "    bY = betXY[:, 1].reshape(1, 1, m)\n",
    "\n",
    "    minX = cp.mean(bX) - (5 * cp.std(bX))\n",
    "    maxX = cp.mean(bX) + (5 * cp.std(bX))\n",
    "    minY = cp.mean(bY) - (5 * cp.std(bY))\n",
    "    maxY = cp.mean(bY) + (5 * cp.std(bY))\n",
    "\n",
    "    dX = (maxX - minX) / (bn - 1)\n",
    "    dY = (maxY - minY) / (bn - 1)\n",
    "    minX = minX - dX/2\n",
    "    maxX = maxX + dX/2\n",
    "    minY = minY - dY/2\n",
    "    maxY = maxY + dY/2\n",
    "\n",
    "    bXi = cp.ceil((bX - minX) / dX).astype(int)\n",
    "    bYi = cp.ceil((bY - minY) / dY).astype(int)\n",
    "    bXi[bXi < 1] = 1\n",
    "    bXi[bXi > bn] = bn\n",
    "    bYi[bYi < 1] = 1\n",
    "    bYi[bYi > bn] = bn\n",
    "\n",
    "    j = cp.arange(bn)\n",
    "    vi = 2 * cp.pi * (j - bn/2) / (maxX - minX - dX)\n",
    "    wj = 2 * cp.pi * (j - bn/2) / (maxY - minY - dY)\n",
    "    Rx = cp.tile(vi, (bn, 1))\n",
    "    Ry = cp.tile(wj, (bn, 1)).T\n",
    "\n",
    "    Rx_sq = Rx**2\n",
    "    Ry_sq = Ry**2\n",
    "    Rx_Ry = Rx*Ry\n",
    "    \n",
    "    mf_init = -2 * cp.log(cp.complex128(-1)) * (cp.tile(((minX + dX/2) / (maxX - minX - dX)) * j, (bn, 1)) + cp.tile(((minY + dY/2) / (maxY - minY - dX)) * j.reshape(-1, 1), (1, bn)))\n",
    "    mf = mf_init\n",
    "\n",
    "    j_col = j[:, cp.newaxis]\n",
    "    j_row = j[cp.newaxis, :]\n",
    "\n",
    "    FFTmod_init = (1 / ((maxX - minX - dX) * (maxY - minY - dY))) * (cp.complex128(-1))**(bn * ((minX + dX/2) / (maxX - minX - dX) + (minY + dY/2) / (maxY - minY - dY)) + (j_col + j_row))\n",
    "    FFTmod = FFTmod_init.reshape(bn, bn)\n",
    "\n",
    "    ixF = cp.column_stack((bXi[0, 0, :] - 1, bYi[0, 0, :] - 1))  # -1 for 0-based indexing\n",
    "\n",
    "    return m, Rx, Ry, mf, FFTmod, ixF, Rx_sq, Ry_sq, Rx_Ry\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precompute_values_twoStep(betXY, piX, piU, piY, nX, nY, bn=2**8):\n",
    "    m = betXY.shape[0]\n",
    "    bn = m\n",
    "\n",
    "    bX = betXY[:, 0].reshape(1, 1, m)\n",
    "    bY = betXY[:, 1].reshape(1, 1, m)\n",
    "\n",
    "    minX = np.mean(bX) - (5 * np.std(bX))\n",
    "    maxX = np.mean(bX) + (5 * np.std(bX))\n",
    "    minY = np.mean(bY) - (5 * np.std(bY))\n",
    "    maxY = np.mean(bY) + (5 * np.std(bY))\n",
    "\n",
    "    dX = (maxX - minX) / (bn - 1)\n",
    "    dY = (maxY - minY) / (bn - 1)\n",
    "    minX = minX - dX/2\n",
    "    maxX = maxX + dX/2\n",
    "    minY = minY - dY/2\n",
    "    maxY = maxY + dY/2\n",
    "\n",
    "    bXi = np.ceil((bX - minX) / dX).astype(int)\n",
    "    bYi = np.ceil((bY - minY) / dY).astype(int)\n",
    "    bXi[bXi < 1] = 1\n",
    "    bXi[bXi > bn] = bn\n",
    "    bYi[bYi < 1] = 1\n",
    "    bYi[bYi > bn] = bn\n",
    "\n",
    "    j = np.arange(bn)\n",
    "    vi = 2 * np.pi * (j - bn/2) / (maxX - minX - dX)\n",
    "    wj = 2 * np.pi * (j - bn/2) / (maxY - minY - dY)\n",
    "    Rx = np.tile(vi, (bn, 1))\n",
    "    Ry = np.tile(wj, (bn, 1)).T\n",
    "\n",
    "    Rx_sq = Rx**2\n",
    "    Ry_sq = Ry**2\n",
    "    Rx_Ry = Rx*Ry\n",
    "    \n",
    "    mf_init = -2 * np.log(np.complex128(-1)) * (np.tile(((minX + dX/2) / (maxX - minX - dX)) * j, (bn, 1)) + np.tile(((minY + dY/2) / (maxY - minY - dX)) * j.reshape(-1, 1), (1, bn)))\n",
    "    mf = np.array(mf_init)\n",
    "\n",
    "    FFTmod_init = (1 / ((maxX - minX - dX) * (maxY - minY - dY))) * (np.complex128(-1))**(bn * ((minX + dX/2) / (maxX - minX - dX) + (minY + dY/2) / (maxY - minY - dY)) + np.add.outer(j, j))\n",
    "    FFTmod = FFTmod_init.reshape(bn, bn)\n",
    "\n",
    "    ixF = np.column_stack((bXi[0, 0, :] - 1, bYi[0, 0, :] - 1))  # -1 for 0-based indexing\n",
    "\n",
    "    return m,  Rx, Ry, mf, FFTmod, ixF, Rx_sq, Ry_sq, Rx_Ry\n",
    "\n",
    "def pairTrait_twoStep_likelihood_old(theta, betXY, w8s, precomputed_values, model=\"comp\"):\n",
    "    # Unpack precomputed values\n",
    "    m,  Rx, Ry,  mf, FFTmod, ixF, Rx_sq, Ry_sq, Rx_Ry = precomputed_values\n",
    "    \n",
    "    # Extract parameters from theta\n",
    "    h2X = np.abs(theta[0])\n",
    "    h2Y = np.abs(theta[1])\n",
    "\n",
    "    if model == \"X1\":\n",
    "        tX = np.abs(theta[2])\n",
    "        tY = theta[3]\n",
    "        axy = theta[4]\n",
    "        ayx = 0\n",
    "        iXY = theta[6]\n",
    "    elif model == \"X2\":\n",
    "        tX = np.abs(theta[2])\n",
    "        tY = theta[3]\n",
    "        axy = 0\n",
    "        ayx = theta[5]\n",
    "        iXY = theta[6]\n",
    "    elif model == \"X3\":\n",
    "        tX = np.abs(theta[2])\n",
    "        tY = theta[3]\n",
    "        axy = 0\n",
    "        ayx = 0\n",
    "        iXY = theta[6]\n",
    "\n",
    "    sigX_sq = h2X/(piX*m)\n",
    "    sigU_sq = 1/(piU*m)\n",
    "    sigY_sq = h2Y/(piY*m)\n",
    "    \n",
    "    Rp = np.array([[iX/nX, iXY/np.sqrt(nX*nY)], [iXY/np.sqrt(nX*nY), iY/nY]])\n",
    "\n",
    "    # Compute coX, coY, coU, Lx, and Ly\n",
    "    coX = Rx + axy * Ry\n",
    "    coY = Ry + ayx * Rx\n",
    "    coU = sigU_sq * ((tX + ayx * tY) * Rx + (tY + axy * tX) * Ry)\n",
    "\n",
    "    Lx = - m * (1 - np.exp(-0.5 * sigX_sq * coX**2))\n",
    "    Ly = - m * (1 - np.exp(-0.5 * sigY_sq * coY**2))\n",
    "    Le = -0.5 * ((Rp[0, 0] * Rx_sq + Rp[1, 1] * Ry_sq) + 2 * Rp[0, 1] * (Rx_Ry))\n",
    "\n",
    "    # Calculate phi, FFT, FFT0\n",
    "    phi = np.exp(Lx + Ly + Le + mf)\n",
    "    FFT = fft(phi, axis=0)\n",
    "    FFT0 = np.real(FFT * FFTmod)\n",
    "\n",
    "    # Extract probability densities for observed effect sizes\n",
    "    pfE = FFT0[ixF[:, 0], ixF[:, 1]]\n",
    "    selu = np.where(pfE > 0)[0]\n",
    "    pfE = pfE[selu]\n",
    "    my_w8s = w8s[selu]\n",
    "\n",
    "    # Calculate log-likelihood\n",
    "    logL = -np.mean(np.log(pfE * my_w8s))\n",
    "\n",
    "    return logL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairTrait_twoStep_likelihood(theta, betXY, w8s, precomputed_values, model=\"comp\"):\n",
    "    # Transfer arrays to GPU memory\n",
    "    theta = cp.array(theta)\n",
    "    #betXY = cp.array(betXY)\n",
    "    #w8s = cp.array(w8s)\n",
    "    #precomputed_values = [cp.array(value) for value in precomputed_values]\n",
    "\n",
    "    # Unpack precomputed values\n",
    "    m, Rx, Ry, mf, FFTmod, ixF, Rx_sq, Ry_sq, Rx_Ry = precomputed_values\n",
    "    \n",
    "    # Extract parameters from theta\n",
    "    h2X = cp.abs(theta[0])\n",
    "    h2Y = cp.abs(theta[1])\n",
    "\n",
    "    if model == \"X1\":\n",
    "        tX = cp.abs(theta[2])\n",
    "        tY = theta[3]\n",
    "        axy = theta[4]\n",
    "        ayx = 0\n",
    "        iXY = theta[6]\n",
    "    elif model == \"X2\":\n",
    "        tX = cp.abs(theta[2])\n",
    "        tY = theta[3]\n",
    "        axy = 0\n",
    "        ayx = theta[5]\n",
    "        iXY = theta[6]\n",
    "    elif model == \"X3\":\n",
    "        tX = cp.abs(theta[2])\n",
    "        tY = theta[3]\n",
    "        axy = 0\n",
    "        ayx = 0\n",
    "        iXY = theta[6]\n",
    "\n",
    "    sigX_sq = h2X/(piX*m)\n",
    "    sigU_sq = 1/(piU*m)\n",
    "    sigY_sq = h2Y/(piY*m)\n",
    "    \n",
    "    Rp = cp.array([[cp.abs(iX/nX), iXY/cp.sqrt(nX*nY)], [iXY/cp.sqrt(nX*nY), cp.abs(iY/nY)]])\n",
    "\n",
    "    # Compute coX, coY, coU, Lx, and Ly\n",
    "    coX = Rx + axy * Ry\n",
    "    coY = Ry + ayx * Rx\n",
    "    coU = sigU_sq * ((tX + ayx * tY) * Rx + (tY + axy * tX) * Ry)\n",
    "\n",
    "    Lx = - m * (1 - cp.exp(-0.5 * sigX_sq * coX**2))\n",
    "    Ly = - m * (1 - cp.exp(-0.5 * sigY_sq * coY**2))\n",
    "    Le = -0.5 * ((Rp[0, 0] * Rx_sq + Rp[1, 1] * Ry_sq) + 2 * Rp[0, 1] * (Rx_Ry))\n",
    "    Lu = -m * piU * (1 - cp.exp(-0.5 * coU**2))\n",
    "    # Calculate phi, FFT, FFT0\n",
    "    phi = cp.exp(Lx + Ly + Le + mf)\n",
    "    FFT = fft(phi, axis=0)\n",
    "    FFT0 = cp.real(FFT * FFTmod)\n",
    "\n",
    "    # Extract probability densities for observed effect sizes\n",
    "    pfE = FFT0[ixF[:, 0], ixF[:, 1]]\n",
    "    selu = cp.where(pfE > 0)[0]\n",
    "    pfE = pfE[selu]\n",
    "    my_w8s = w8s[selu]\n",
    "\n",
    "    # Calculate log-likelihood\n",
    "    logL = -cp.mean(cp.log(pfE * my_w8s))\n",
    "\n",
    "    return logL.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.76200165]\n",
      "nan\n",
      "nan\n",
      "1.0893729900540994\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# sanity check mememememmememememmemememeeeeeeemee\n",
    "\n",
    "n = 50000  # Sample size (number of individuals)\n",
    "p = 100  # Number of SNPs\n",
    "num_X1 = num_X2 = num_X3 = 0 # Number of genes\n",
    "num_X1=1\n",
    "nX=nY=n\n",
    "def sim_hr(p, pi, sig):\n",
    "    hX = cp.random.binomial(1, pi, p).astype(cp.float32)\n",
    "    seli = cp.where(hX == 1.0)\n",
    "    tmp = cp.random.normal(0, sig, len(seli[0]))\n",
    "    hX[seli] = tmp\n",
    "    return hX\n",
    "\n",
    "piX = 0.05  # Proportion for X.\n",
    "h2X = .3 # Direct heritability of X's\n",
    "piY = 0.1  # Proportion for Y.\n",
    "h2Y = .2 # Direct heritability of Y\n",
    "\n",
    "qY = .1 # Y variance explained by confounder\n",
    "q1 = q2 = q3 = 0.2 # X variance explained by confounder\n",
    "sigX = cp.sqrt(h2X / (p * piX))\n",
    "sigY = cp.sqrt(h2Y / (p * piY))\n",
    "\n",
    "alp1 = 0.1\n",
    "alp2 = 0.25\n",
    "\n",
    "piU = 0.1  # Proportion for U.\n",
    "# h2U = 0 # Direct heritability of U\n",
    "# sigU = 0\n",
    "\n",
    "# 1. Simulate the SNP matrix G\n",
    "q = cp.random.uniform(0.05, 0.5, p)\n",
    "G = cp.array([(cp.random.binomial(2, qq, size=n) - 2 * qq) / cp.sqrt(2 * qq * (1 - qq)) for qq in q]).T\n",
    "\n",
    "# 2. Simulate U (unobserved confounder)\n",
    "U = cp.random.normal(0, 1, n)\n",
    "\n",
    "iX = 1;\n",
    "iY = 1;\n",
    "iXY = 0;\n",
    "\n",
    "tX=0\n",
    "tY=0\n",
    "\n",
    "# 3. Simulate gene expressions X\n",
    "# X1\n",
    "gamma_1_list = [sim_hr(p, piX, sigX) for _ in range(num_X1)]\n",
    "e_1_list = [cp.random.normal(0, cp.sqrt(1 - h2X - q1**2), n) for _ in range(num_X1)]\n",
    "X1 = cp.array([(q1*U + G @ gamma_1_list[idx] + e_1_list[idx]) for idx in range(num_X1)]).T\n",
    "# X3\n",
    "gamma_3_list = [sim_hr(p, piX, sigX) for _ in range(num_X3)]\n",
    "e_3_list = [cp.random.normal(0, cp.sqrt(1 - h2X - q3**2), n) for _ in range(num_X3)]\n",
    "X3 = cp.array([(q3*U + G @ gamma_3_list[idx] + e_3_list[idx]) for idx in range(num_X3)]).T\n",
    "# Y\n",
    "gamma_y = sim_hr(p, piY, sigY)\n",
    "e_y = cp.random.normal(0, cp.sqrt(1 - h2Y - qY**2 - 2 * num_X1 * (qY * alp1 * q1) - num_X1 * (1 + (num_X1-1)*q1**2) * alp1**2), n)\n",
    "Y = qY*U + cp.sum(alp1*X1, axis=1) + G @ gamma_y + e_y\n",
    "# X2\n",
    "gamma_2_list = [sim_hr(p, piX, sigX) for _ in range(num_X2)]\n",
    "e_2_list = [cp.random.normal(0, cp.sqrt(1 - h2X - q2**2 - alp2**2 - 2 * qY * alp2 * q2 \\\n",
    "    - 2 * num_X1 * alp1 * alp2 * q1 * (q2 + alp2 * qY) - num_X1 * (num_X1-1) * q1**2 * alp1**2 * alp2**2), n) for _ in range(num_X2)]\n",
    "X2 = cp.array([(q2 * U + alp2 * Y + G @ gamma_2_list[idx] + e_2_list[idx]) for idx in range(num_X2)]).T\n",
    "\n",
    "# To print the variances, we need to transfer the data back to the host (CPU)\n",
    "# and convert it back to NumPy arrays\n",
    "print(cp.asnumpy(cp.var(X1, axis=0)))\n",
    "print(cp.asnumpy(cp.var(X2, axis=0)))\n",
    "print(cp.asnumpy(cp.var(X3, axis=0)))\n",
    "print(cp.asnumpy(cp.var(Y)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_linregress(x, y):\n",
    "    # Assuming x and y are both cupy arrays and x is a single feature.\n",
    "    # x needs to be reshaped to a column vector if it's a 1D array.\n",
    "    if x.ndim == 1:\n",
    "        x = x[:, cp.newaxis]\n",
    "        \n",
    "    # Adding a column of ones to x to represent the intercept coefficients.\n",
    "    X = cp.concatenate([cp.ones((x.shape[0], 1), dtype=x.dtype), x], axis=1)\n",
    "    \n",
    "    # Calculating the coefficients using the least squares method.\n",
    "    # We use the formula (X^T * X)^(-1) * X^T * y\n",
    "    coeffs = cp.linalg.inv(X.T @ X) @ X.T @ y\n",
    "    \n",
    "    # The slope is the second coefficient, and the intercept is the first.\n",
    "    slope = coeffs[1]\n",
    "    intercept = coeffs[0]\n",
    "    \n",
    "    # We don't calculate r_value, p_value, std_err for simplicity.\n",
    "    # If you need these, additional calculations are required.\n",
    "    return slope, intercept\n",
    "\n",
    "# Now we will use this function to replace linregress in your loops:\n",
    "beta_Y = cp.array([simple_linregress(G[:, j], Y.ravel())[0] for j in range(p)])\n",
    "\n",
    "beta_X1 = cp.stack([\n",
    "    cp.array([simple_linregress(G[:, j], X1[:, i])[0] for j in range(p)])\n",
    "    for i in range(num_X1)\n",
    "])\n",
    "\n",
    "#beta_X2 = cp.stack([\n",
    "#    cp.array([simple_linregress(G[:, j], X2[:, i])[0] for j in range(p)])\n",
    "#    for i in range(num_X2)\n",
    "#])\n",
    "\n",
    "#beta_X3 = cp.stack([\n",
    "#    cp.array([simple_linregress(G[:, j], X3[:, i])[0] for j in range(p)])\n",
    "#    for i in range(num_X3)\n",
    "#])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def singleTrait_function(betX, nX, par_df):\n",
    "    mLL = []\n",
    "    par = []\n",
    "    conv = []\n",
    "    betX_cp = cp.array(betX)\n",
    "    precomputed_data = precompute_values_gpu(betX_cp)\n",
    "    w8s = cp.repeat(cp.abs(1),p)\n",
    "    \n",
    "    for idx in range(par_df.shape[0]):\n",
    "        x = par_df.iloc[idx].to_list()\n",
    "        # Define objective function for optimization\n",
    "        def objective(theta):\n",
    "            return singleTrait_likelihood(theta, betX, w8s, nX, *precomputed_data, bn=2**7)\n",
    "        # Run optimization\n",
    "        res = minimize(objective, x, method='Nelder-Mead', options={'maxiter': 5000})\n",
    "        # Collect results\n",
    "        mLL.append(res.fun)\n",
    "        par.append(res.x)\n",
    "        conv.append(res.success)\n",
    "    return mLL, np.array(par), conv\n",
    "# singleTrait_likelihood(theta, betX, w8s, nX, bn=2**7, bins=10)\n",
    "def pairTrait_function(betXY, nX, nY, par_df, model):\n",
    "    mLL = []\n",
    "    par = []\n",
    "    conv = []\n",
    "    betXY = cp.array(betXY)\n",
    "\n",
    "    precomputed_values = precompute_values_twoStep_gpu(betXY, piX, piU, piY, nX, nY)\n",
    "    w8s = cp.repeat(cp.abs(1),p)\n",
    "\n",
    "    for idx in range(par_df.shape[0]):\n",
    "        x = par_df.iloc[idx].to_list()\n",
    "        def objective(theta):\n",
    "            return pairTrait_twoStep_likelihood(theta, betXY, w8s, precomputed_values, model=model)\n",
    "        res = minimize(objective, x, method='Nelder-Mead', options={'maxiter': 5000})\n",
    "        mLL.append(res.fun)\n",
    "        par.append(res.x)\n",
    "        conv.append(res.success)\n",
    "    return mLL, np.array(par), conv\n",
    "    \n",
    "# pairTrait_twoStep_likelihood(theta, betXY, w8s, pi_U=0.1, pi_X=None, pi_Y=None, i_X=None, i_Y=None, nX=None, nY=None, model=\"comp\", bn=2**8, bins=15)\n",
    "# test = optim(theta, lhcMR:::pairTrait_twoStep_likelihood,\n",
    "#         betX=betXY, pi1=pi1, sig1=sig1, w8s=w8s, M=M,\n",
    "#         m0=m0, nX=nX, nY=nY, pi_U=piU, pi_X=piX, pi_Y=piY, i_X=iX, i_Y=iY,\n",
    "#         bn=2^7, bins=10,\n",
    "#         method = \"Nelder-Mead\",\n",
    "#         control = list(maxit = 5e3,\n",
    "#                         parscale = parscale2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def singleTrait_function_plot(betX, nX, par_df):\n",
    "    # Extract only the first row of par_df\n",
    "    fixed_params = par_df.iloc[0, 2:].to_list()  # Get the rest of the parameters after the first two\n",
    "    mLL = []\n",
    "    param_1_values = np.linspace(0.001, 1, 20)\n",
    "    param_2_values = np.linspace(0.001, 1, 20)\n",
    "    betX_cp = cp.array(betX)\n",
    "    precomputed_data = precompute_values_gpu(betX_cp)\n",
    "    w8s = cp.repeat(cp.abs(1), p)\n",
    "    \n",
    "    # Calculate likelihood for each combination of first two parameters\n",
    "    for param_1 in param_1_values:\n",
    "        for param_2 in param_2_values:\n",
    "            params = [param_1, param_2] + fixed_params\n",
    "            likelihood = singleTrait_likelihood(params, betX, w8s, nX, *precomputed_data, bn=2**7)\n",
    "            mLL.append(likelihood)\n",
    "    \n",
    "    # Reshape mLL to a 20x20 grid to match param_1_values and param_2_values\n",
    "    mLL_grid = np.reshape(mLL, (20, 20))\n",
    "\n",
    "    # Create a 3D plot\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    # Create a meshgrid for the parameters to plot the surface\n",
    "    param_1_mesh, param_2_mesh = np.meshgrid(param_1_values, param_2_values)\n",
    "\n",
    "    # Plot the surface\n",
    "    ax.plot_surface(param_1_mesh, param_2_mesh, mLL_grid, cmap='viridis')\n",
    "\n",
    "    # Set labels\n",
    "    ax.set_xlabel('Parameter 1')\n",
    "    ax.set_ylabel('Parameter 2')\n",
    "    ax.set_zlabel('-Log Likelihood')\n",
    "\n",
    "    # Show plot\n",
    "    plt.show()\n",
    "\n",
    "    return mLL_grid, param_1_values, param_2_values\n",
    "\n",
    "\n",
    "def pairTrait_function_plot(betXY, nX, nY, par_df, model):\n",
    "    # Assume piX, piU, piY have been defined elsewhere in your code\n",
    "    mLL_grid = np.zeros((20, 20))  # Create a grid for the likelihood values\n",
    "    param_1_values = np.linspace(0.001, 1, 20)\n",
    "    param_2_values = np.linspace(0.001, 1, 20)\n",
    "    betXY_cp = cp.array(betXY)\n",
    "    precomputed_values = precompute_values_twoStep_gpu(betXY_cp, piX, piU, piY, nX, nY)\n",
    "    w8s = cp.repeat(cp.abs(1), p)\n",
    "\n",
    "    # Only use the first row of par_df for the fixed parameters\n",
    "    fixed_params = par_df.iloc[0, 2:].to_list()\n",
    "\n",
    "    # Iterate over all combinations of the first two parameters\n",
    "    for i, param_1 in enumerate(param_1_values):\n",
    "        for j, param_2 in enumerate(param_2_values):\n",
    "            params = [param_1, param_2] + fixed_params\n",
    "            likelihood = pairTrait_twoStep_likelihood(params, betXY_cp, w8s, precomputed_values, model=model)\n",
    "            mLL_grid[i, j] = likelihood\n",
    "\n",
    "    # Create a 3D plot\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    # Create a meshgrid for the parameters to plot the surface\n",
    "    param_1_mesh, param_2_mesh = np.meshgrid(param_1_values, param_2_values)\n",
    "\n",
    "    # Plot the surface\n",
    "    ax.plot_surface(param_1_mesh, param_2_mesh, mLL_grid, cmap='viridis')\n",
    "\n",
    "    # Set labels and titles\n",
    "    ax.set_xlabel('Parameter 1')\n",
    "    ax.set_ylabel('Parameter 2')\n",
    "    ax.set_zlabel('-Log Likelihood')\n",
    "    ax.set_title('Likelihood Surface for Pair of Traits')\n",
    "\n",
    "    # Show plot\n",
    "    plt.show()\n",
    "\n",
    "    return mLL_grid, param_1_values, param_2_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def singleTrait_function_bayes(betX, nX, par_df):\n",
    "    mLL = []\n",
    "    par = []\n",
    "    conv = []\n",
    "\n",
    "    betX_cp = cp.array(betX)\n",
    "    precomputed_data = precompute_values_gpu(betX_cp)\n",
    "    w8s = cp.repeat(cp.abs(1),p)\n",
    "    # Define the objective function for Bayesian Optimization\n",
    "    # The parameters should be unpacked from **kwargs for flexibility.\n",
    "    def objective(**kwargs):\n",
    "        theta = list(kwargs.values())  # Convert the values of the parameters to a list\n",
    "        return -singleTrait_likelihood(theta, betX_cp, w8s, nX, *precomputed_data, bn=2**7)\n",
    "        # Note: We negate the likelihood because BayesianOptimization tries to maximize the function,\n",
    "        # but we're originally minimizing a negative likelihood.\n",
    "\n",
    "    # Assuming all parameters in par_df are within the same bounds. Adjust if needed.\n",
    "    # Extract parameter names and create bounds\n",
    "    param_names = par_df.columns.tolist()\n",
    "    pbounds = {name: (0.0001, 1) for name in param_names}  # Modify min_bound and max_bound as needed\n",
    "    pbounds['sp_piX'] = (0.001, 0.1)\n",
    "    pbounds['sp_h2X'] = (0.1, 0.5)\n",
    "    pbounds['sp_iX'] = (0, 2)\n",
    "    print(pbounds)\n",
    "\n",
    "    optimizer = BayesianOptimization(\n",
    "        f=objective,\n",
    "        pbounds=pbounds,\n",
    "        random_state=1,\n",
    "    )\n",
    "\n",
    "    optimizer.set_gp_params(alpha=1e-3)\n",
    "    # Run Bayesian Optimization\n",
    "    optimizer.maximize(\n",
    "        init_points=5,  # Adjust as needed\n",
    "        n_iter=20\n",
    "    )\n",
    "\n",
    "    for res in optimizer.res:  # Iterate over results\n",
    "        mLL.append(-res['target'])  # We negate again to get the original negative likelihood value\n",
    "        par.append(list(res['params'].values()))\n",
    "        # BayesianOptimization doesn't directly give a success flag. You might want to derive one based on some criterion.\n",
    "        conv.append(True)  # Placeholder. Modify as needed.\n",
    "\n",
    "    print(optimizer.max)\n",
    "    return mLL, np.array(par), conv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallel_function(idx, par_df_row, betXY, w8s, precomputed_values, model):\n",
    "    def objective(theta):\n",
    "        return pairTrait_twoStep_likelihood(theta, betXY, w8s, precomputed_values, model=model)\n",
    "    res = minimize(objective, par_df_row, method='Nelder-Mead', options={'maxiter': 5000})\n",
    "    return res.fun, res.x, res.success\n",
    "\n",
    "def pairTrait_function_threaded(betXY, nX, nY, par_df, model):\n",
    "    mLL = []\n",
    "    par = []\n",
    "    conv = []\n",
    "    betXY = cp.array(betXY)\n",
    "\n",
    "    precomputed_values = precompute_values_twoStep_gpu(betXY, piX, piU, piY, nX, nY)\n",
    "    w8s = cp.repeat(cp.abs(1), p)\n",
    "\n",
    "    # Use ProcessPoolExecutor to parallelize\n",
    "    results = []\n",
    "    with concurrent.futures.ProcessPoolExecutor(max_workers=16) as executor:  # adjust max_workers as needed\n",
    "        iterable_args = [(idx, par_df.iloc[idx].to_list(), betXY, w8s, precomputed_values, model) for idx in range(par_df.shape[0])]\n",
    "        results = list(executor.map(lambda args: parallel_function(*args), iterable_args))\n",
    "\n",
    "    # Now, unpack the results into mLL, par, and conv\n",
    "    mLL = [res[0] for res in results]\n",
    "    par = [res[1] for res in results]\n",
    "    conv = [res[2] for res in results]\n",
    "\n",
    "    return mLL, np.array(par), conv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def pairTrait_function_bayes(betXY, nX, nY, par_df, model):\n",
    "    mLL = []\n",
    "    par = []\n",
    "    conv = []\n",
    "\n",
    "    betXY = cp.array(betXY)\n",
    "    precomputed_values = precompute_values_twoStep_gpu(betXY, piX, piU, piY, nX, nY)\n",
    "    w8s = cp.repeat(cp.abs(1),p)\n",
    "\n",
    "    # Define the objective function for Bayesian Optimization\n",
    "    def objective(theta0, theta1, theta2, theta3, theta4, theta5, theta6):\n",
    "        theta = [theta0, theta1, theta2, theta3, theta4, theta5, theta6]\n",
    "        return -pairTrait_twoStep_likelihood(theta, betXY, w8s, precomputed_values, model=model)\n",
    "\n",
    "    # Getting bounds\n",
    "    pbounds = {\n",
    "        'theta0': (0.1, 0.5), #(par_df['sp_h2X'].min(), par_df['sp_h2X'].max()),\n",
    "        'theta1': (0.1, 0.5), #(par_df['sp_h2Y'].min(), par_df['sp_h2Y'].max()),\n",
    "        'theta2': (0.001, 0.5), #(par_df['sp_tX'].min(), par_df['sp_tX'].max()),\n",
    "        'theta3': (-0.5, 0.5), #(par_df['sp_tY'].min(), par_df['sp_tY'].max()),\n",
    "        'theta4': (0.01, 0.5), #(par_df['sp_axy'].min(), par_df['sp_axy'].max()),\n",
    "        'theta5': (0.01, 0.5), #(par_df['sp_ayx'].min(), par_df['sp_ayx'].max()),\n",
    "        'theta6': (0.95, 1.05), #(par_df['sp_iXY'].min(), par_df['sp_iXY'].max()),\n",
    "    }\n",
    "\n",
    "    optimizer = BayesianOptimization(\n",
    "        f=objective,\n",
    "        pbounds=pbounds,\n",
    "        random_state=1,\n",
    "    )\n",
    "\n",
    "    optimizer.maximize(\n",
    "        init_points=15,\n",
    "        n_iter=15,  # Adjust the number of iterations as needed\n",
    "    )\n",
    "\n",
    "    mLL.append(-optimizer.max['target'])\n",
    "    par.append(optimizer.max['params'].values())\n",
    "    conv.append(True)  # Bayesian optimization always converges\n",
    "    #print(optimizer.max)\n",
    "    return mLL, np.array(par), conv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   ## SP calculation\n",
    "SP = 10\n",
    "nSP = 10\n",
    "#   sp_piX = runif(SP,0,0.01)\n",
    "#   sp_h2X = runif(SP,0,0.5)\n",
    "#   sp_iX = runif(SP,0.5,1.5)\n",
    "sp_piX = np.random.uniform(0.001, 0.02, SP)\n",
    "sp_h2X = np.random.uniform(0.15, 0.5, SP)\n",
    "sp_iX = np.random.uniform(0.5, 1.5, SP)\n",
    "#   para=cbind(sp_piX,sp_h2X,sp_iX)\n",
    "#   sp_mat=matrix(unlist(para), ncol=SP, byrow = FALSE)\n",
    "#   colnames(sp_mat)=colnames(para)\n",
    "#   par.df = data.frame(par=I(apply(sp_mat,1,as.list)))\n",
    "para = np.column_stack((sp_piX, sp_h2X, sp_iX))\n",
    "par_df = pd.DataFrame(para)\n",
    "par_df.columns = ['sp_piX', 'sp_h2X', 'sp_iX']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 3.7905 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "test_exp = singleTrait_function(beta_X1[0], nX, par_df)\n",
    "test_out = singleTrait_function(beta_Y, nY, par_df)\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "duration = end_time - start_time\n",
    "print(f\"Time taken: {duration:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.04554643 -1.90658156  0.72063537]\n",
      " [ 0.04554543  0.55062254  0.72063041]\n",
      " [ 0.04554619  0.55612685  0.72063103]\n",
      " [ 0.04554753 -1.10179476  0.7206292 ]\n",
      " [ 0.04554619  0.4309168   0.72063114]\n",
      " [ 0.04554619  0.44336126  0.72063114]\n",
      " [ 0.04554648 -1.67515296  0.72062638]\n",
      " [ 0.0455425   0.20610085  0.72065824]\n",
      " [ 0.04554621 -1.72235168  0.72062916]\n",
      " [ 0.04554704  1.71261173  0.7206312 ]]\n"
     ]
    }
   ],
   "source": [
    "print(test_exp[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   test.exp <- parallel::mclapply(par.df[[1]], function(x) {\n",
    "#     theta = unlist(x) #theta = unlist(par.df[[1]][1])\n",
    "#     test1 = optim(theta, lhcMR:::singleTrait_likelihood,\n",
    "#                   betX=betXY[,1], pi1=pi1, sig1=sig1, w8s=wd, M=M,\n",
    "#                   m0=m0, nX=nX, bn=2^7, bins=10,\n",
    "#                   method = \"Nelder-Mead\",\n",
    "#                   control = list(maxit = 5e3))\n",
    "    \n",
    "#     list(\"mLL\"=test1$value,\"par\"=test1$par,\"conv\"=test1$convergence)\n",
    "#   }, mc.cores = nCores)\n",
    "#   test.exp = as.data.frame(t(matrix(unlist(test.exp), nrow=length(unlist(test.exp[1])))))\n",
    "\n",
    "\n",
    "#   res_exp_min = test.exp[which(test.exp$mLL == min(test.exp$mLL)), ]\n",
    "#   res_exp = abs(res_exp_min[2:4]) #piX,h2X,iX\n",
    "#   res_out_min = test.out[which(test.out$mLL == min(test.out$mLL)), ]\n",
    "#   res_out = abs(res_out_min[2:4]) #piY,h2Y,iY\n",
    "res_exp = test_exp[1][np.argmin(test_exp[0])]\n",
    "res_out = test_out[1][np.argmin(test_out[0])]\n",
    "#   pi_X = as.numeric(res_exp[1])\n",
    "#   pi_Y = as.numeric(res_out[1])\n",
    "#   h2_x = as.numeric(res_exp[2]) #total heritability, not used\n",
    "#   h2_y = as.numeric(res_out[2]) #total heritability, not used\n",
    "#   i_X = as.numeric(res_exp[3])\n",
    "#   i_Y = as.numeric(res_out[3])\n",
    "pi_X = res_exp[0]\n",
    "pi_Y = res_out[0]\n",
    "h2_x = res_exp[1]\n",
    "h2_y = res_out[1]\n",
    "i_X = res_exp[2]\n",
    "i_Y = res_out[2]\n",
    "pi_X_df = pd.DataFrame(test_exp[1])\n",
    "pi_Y_df = pd.DataFrame(test_out[1])\n",
    "pi_X_df.columns = ['piX', 'h2X', 'iX']\n",
    "pi_Y_df.columns = ['piY', 'h2Y', 'iY']\n",
    "pi_X_df['mLL'] = test_exp[0]\n",
    "pi_Y_df['mLL'] = test_out[0]\n",
    "#   # Generate the rest of the starting points \n",
    "#   sp_tX = runif(nSP,0,0.5)\n",
    "#   sp_tY = runif(nSP,-0.5,0.5)\n",
    "#   sp_h2X = max(0,h2_x-(sp_tX^2))\n",
    "#   sp_h2Y = max(0,h2_y-(sp_tY^2))\n",
    "#   sp_axy = replicate(nSP, (alp+runif(1,-0.1,0.1)))\n",
    "#   sp_ayx = replicate(nSP, (bet+runif(1,-0.1,0.1)))\n",
    "#   sp_iXY = replicate(nSP, (iXY+runif(1,-0.05,0.05))) #rep(i_XY,50)\n",
    "sp_tX = np.random.uniform(0., 0.5, nSP)\n",
    "sp_tY = np.random.uniform(-0.5, 0.5, nSP)\n",
    "sp_h2X = h2_x - np.square(sp_tX)\n",
    "sp_h2X[sp_h2X<0] = 0\n",
    "sp_h2Y = h2_y - np.square(sp_tY)\n",
    "sp_h2Y[sp_h2Y<0] = 0\n",
    "sp_axy = np.random.uniform(0.001, 0.3, nSP)\n",
    "sp_ayx = np.random.uniform(0.001, 0.5, nSP)\n",
    "sp_iXY = np.random.uniform(0.5, 1.5, nSP) \n",
    "para = np.column_stack((sp_h2X,sp_h2Y,sp_tX,sp_tY,sp_axy,sp_ayx,sp_iXY))\n",
    "par_df = pd.DataFrame(para)\n",
    "par_df.columns = ['sp_h2X', 'sp_h2Y', 'sp_tX', 'sp_tY', 'sp_axy', 'sp_ayx', 'sp_iXY']\n",
    "betXY = np.column_stack((beta_X1[0], beta_Y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>piX</th>\n",
       "      <th>h2X</th>\n",
       "      <th>iX</th>\n",
       "      <th>mLL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.045546</td>\n",
       "      <td>-1.906582</td>\n",
       "      <td>0.720635</td>\n",
       "      <td>-387.579062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.045545</td>\n",
       "      <td>0.550623</td>\n",
       "      <td>0.720630</td>\n",
       "      <td>-387.579062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.045546</td>\n",
       "      <td>0.556127</td>\n",
       "      <td>0.720631</td>\n",
       "      <td>-387.579062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.045548</td>\n",
       "      <td>-1.101795</td>\n",
       "      <td>0.720629</td>\n",
       "      <td>-387.579062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.045546</td>\n",
       "      <td>0.430917</td>\n",
       "      <td>0.720631</td>\n",
       "      <td>-387.579062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.045546</td>\n",
       "      <td>0.443361</td>\n",
       "      <td>0.720631</td>\n",
       "      <td>-387.579062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.045546</td>\n",
       "      <td>-1.675153</td>\n",
       "      <td>0.720626</td>\n",
       "      <td>-387.579062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.045543</td>\n",
       "      <td>0.206101</td>\n",
       "      <td>0.720658</td>\n",
       "      <td>-387.579061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.045546</td>\n",
       "      <td>-1.722352</td>\n",
       "      <td>0.720629</td>\n",
       "      <td>-387.579062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.045547</td>\n",
       "      <td>1.712612</td>\n",
       "      <td>0.720631</td>\n",
       "      <td>-387.579062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        piX       h2X        iX         mLL\n",
       "0  0.045546 -1.906582  0.720635 -387.579062\n",
       "1  0.045545  0.550623  0.720630 -387.579062\n",
       "2  0.045546  0.556127  0.720631 -387.579062\n",
       "3  0.045548 -1.101795  0.720629 -387.579062\n",
       "4  0.045546  0.430917  0.720631 -387.579062\n",
       "5  0.045546  0.443361  0.720631 -387.579062\n",
       "6  0.045546 -1.675153  0.720626 -387.579062\n",
       "7  0.045543  0.206101  0.720658 -387.579061\n",
       "8  0.045546 -1.722352  0.720629 -387.579062\n",
       "9  0.045547  1.712612  0.720631 -387.579062"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi_X_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>piY</th>\n",
       "      <th>h2Y</th>\n",
       "      <th>iY</th>\n",
       "      <th>mLL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.007226</td>\n",
       "      <td>0.142253</td>\n",
       "      <td>6.168650e-01</td>\n",
       "      <td>-324.735642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.196444</td>\n",
       "      <td>0.231437</td>\n",
       "      <td>1.184664e+00</td>\n",
       "      <td>-296.933562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.585299</td>\n",
       "      <td>-0.000747</td>\n",
       "      <td>-5.388514e-07</td>\n",
       "      <td>-408.101551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.003339</td>\n",
       "      <td>0.203951</td>\n",
       "      <td>8.415431e-07</td>\n",
       "      <td>-428.554472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.027069</td>\n",
       "      <td>0.296601</td>\n",
       "      <td>6.452618e-01</td>\n",
       "      <td>-319.933607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.058348</td>\n",
       "      <td>0.770445</td>\n",
       "      <td>6.796505e-01</td>\n",
       "      <td>-308.895333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.088528</td>\n",
       "      <td>-1.527628</td>\n",
       "      <td>1.501413e-06</td>\n",
       "      <td>-412.006305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.027125</td>\n",
       "      <td>0.704412</td>\n",
       "      <td>6.448985e-01</td>\n",
       "      <td>-319.935845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.007226</td>\n",
       "      <td>0.273787</td>\n",
       "      <td>6.168695e-01</td>\n",
       "      <td>-324.735640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.007228</td>\n",
       "      <td>0.601026</td>\n",
       "      <td>6.168139e-01</td>\n",
       "      <td>-324.735641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        piY       h2Y            iY         mLL\n",
       "0  0.007226  0.142253  6.168650e-01 -324.735642\n",
       "1  0.196444  0.231437  1.184664e+00 -296.933562\n",
       "2  0.585299 -0.000747 -5.388514e-07 -408.101551\n",
       "3  0.003339  0.203951  8.415431e-07 -428.554472\n",
       "4  0.027069  0.296601  6.452618e-01 -319.933607\n",
       "5  0.058348  0.770445  6.796505e-01 -308.895333\n",
       "6  0.088528 -1.527628  1.501413e-06 -412.006305\n",
       "7  0.027125  0.704412  6.448985e-01 -319.935845\n",
       "8  0.007226  0.273787  6.168695e-01 -324.735640\n",
       "9  0.007228  0.601026  6.168139e-01 -324.735641"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi_Y_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#piX = 0.05  # Proportion for X.\n",
    "#h2X = .3 #Direct heritability of X's\n",
    "#piY = 0.1  # Proportion for Y.\n",
    "#h2Y = .2 #Direct heritability of Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0455461916973653 0.0033389606986578254\n"
     ]
    }
   ],
   "source": [
    "print(pi_X, pi_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4433612559438561 0.20395061790877778\n"
     ]
    }
   ],
   "source": [
    "print(h2_x, h2_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 7.1626 seconds\n"
     ]
    }
   ],
   "source": [
    "    # if model == \"X1\":\n",
    "    #     tX = np.abs(theta[2])\n",
    "    #     tY = theta[3]\n",
    "    #     axy = theta[4]\n",
    "    #     ayx = 0\n",
    "    #     iXY = theta[6]    \n",
    "    # elif model == \"X2\":\n",
    "    #     tX = np.abs(theta[2])\n",
    "    #     tY = theta[3]\n",
    "    #     axy = 0\n",
    "    #     ayx = theta[5]\n",
    "    #     iXY = theta[6]\n",
    "    # elif model == \"X3\":\n",
    "    #     tX = np.abs(theta[2])\n",
    "    #     tY = theta[3]\n",
    "    #     axy = 0\n",
    "    #     ayx = 0\n",
    "    #     iXY = theta[6]\n",
    "    \n",
    "piU = 0.1\n",
    "start_time = time.time()\n",
    "\n",
    "test_res1 = pairTrait_function(betXY, nX, nY, par_df, model='X1')\n",
    "results_df1 = pd.DataFrame(test_res1[1])\n",
    "results_df1.columns = ['h2X', 'h2Y', 'tX', 'tY', 'axy', 'ayx', 'iXY']\n",
    "results_df1 = results_df1.drop(columns='ayx')\n",
    "results_df1['mLL'] = test_res1[0]\n",
    "\n",
    "#test_res2 = pairTrait_function(betXY, nX, nY, par_df, model='X2')\n",
    "#results_df2 = pd.DataFrame(test_res2[1])\n",
    "#results_df2.columns = ['h2X', 'h2Y', 'tX', 'tY', 'axy', 'ayx', 'iXY']\n",
    "#results_df2 = results_df2.drop(columns='axy')\n",
    "#results_df2['mLL'] = test_res2[0]\n",
    "\n",
    "#test_res3 = pairTrait_function(betXY, nX, nY, par_df, model='X3')\n",
    "#results_df3 = pd.DataFrame(test_res3[1])\n",
    "#results_df3.columns = ['h2X', 'h2Y', 'tX', 'tY', 'axy', 'ayx', 'iXY']\n",
    "#results_df3 = results_df3.drop(columns=['axy', 'ayx'])\n",
    "#results_df3['mLL'] = test_res3[0]\n",
    "end_time = time.time()\n",
    "\n",
    "duration = end_time - start_time\n",
    "print(f\"Time taken: {duration:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            h2X       h2Y        tX        tY       axy       iXY        mLL\n",
      "0 -6.021428e-11  0.048935  0.047259  0.460542  0.042288  1.413120  -0.025413\n",
      "1  3.144830e-01  0.041918  0.378680 -0.402317  0.294407  1.278977  84.535490\n",
      "2  6.454297e-11  0.155813  0.017743 -0.039032  0.043142  2.167082  -0.948483\n",
      "3  3.764328e-01  0.179024  0.243259  0.170101  0.245311  0.962681  84.569431\n",
      "4 -1.050326e-10  0.150652  0.546842  0.149501  0.297505  2.048536  -0.749792\n",
      "5  2.248073e-01  0.032360  0.469086  0.395109  0.159026  2.284634  83.641848\n",
      "6  3.557393e-01  0.203065  0.296141 -0.031163  0.122148  1.286218  84.225984\n",
      "7 -6.261669e-11  0.019047  0.214738  0.316920  0.081554  4.499360  -5.791462\n",
      "8  9.439604e-02  0.000006  0.611046 -0.578213  0.258805  1.003318   5.643188\n",
      "9  7.163562e-11  0.284000  0.448778 -0.105494  0.041403  2.342083  -0.923322\n"
     ]
    }
   ],
   "source": [
    "min_mLL_index = results_df1['mLL'].idxmin()\n",
    "\n",
    "# Print the row with the lowest 'mLL' value\n",
    "#print(results_df1.loc[min_mLL_index])\n",
    "#print(results_df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate mean and standard deviation\n",
    "mean_axy = results_df1['axy'].mean()\n",
    "std_axy = results_df1['axy'].std()\n",
    "\n",
    "# Create a boxplot\n",
    "plt.figure(figsize=(10, 6))\n",
    "boxplot = plt.boxplot(results_df1['axy'], patch_artist=True)\n",
    "\n",
    "# Color the box in light grey\n",
    "for patch in boxplot['boxes']:\n",
    "    patch.set_facecolor('lightgrey')\n",
    "\n",
    "# Mark the mean with a red diamond\n",
    "plt.scatter(1, mean_axy, marker='D', color='red', label='Mean')\n",
    "\n",
    "# Optionally, you could plot the standard deviation as lines\n",
    "plt.axhline(y=mean_axy + std_axy, color='blue', linestyle='--', label='Mean + 1 SD')\n",
    "plt.axhline(y=mean_axy - std_axy, color='blue', linestyle='--', label='Mean - 1 SD')\n",
    "\n",
    "# Add title and labels\n",
    "plt.title('Boxplot of axy with Mean and Standard Deviation')\n",
    "plt.ylabel('Values of axy')\n",
    "plt.xticks([1], ['axy'])  # Only one box, so we just label the x-axis with 'axy'\n",
    "\n",
    "# Add legend\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15855906714657778\n"
     ]
    }
   ],
   "source": [
    "print(mean_axy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10706018054187408\n"
     ]
    }
   ],
   "source": [
    "print(std_axy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
